{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2cb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_city_coordinates_robust(df):\n",
    "    \"\"\"\n",
    "    Scrapes decimal latitude and longitude for all cities in the DataFrame \n",
    "    from Wikipedia, starting from the Main Page.\n",
    "    \"\"\"\n",
    "    # Initialize the WebDriver (assuming Chrome)\n",
    "    # NOTE: You must have the corresponding driver installed for this to work.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument(\"--headless\") # Uncomment to run without opening the browser GUI\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    base_url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "    \n",
    "    # Create a copy for results and initialize coordinate columns\n",
    "    df_result = df.copy()\n",
    "    df_result['Latitude'] = None\n",
    "    df_result['Longitude'] = None\n",
    "    \n",
    "    print(\"Starting Web Scraping process...\")\n",
    "    \n",
    "    for index, row in df_result.iterrows():\n",
    "        city = row['City']\n",
    "        country = row['Country']\n",
    "        query = f\"{city}, {country}\" # Search format: \"City, Country\"\n",
    "        \n",
    "        try:\n",
    "            driver.get(base_url)\n",
    "            \n",
    "            # Use WebDriverWait to ensure the search bar is clickable\n",
    "            search_input = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.NAME, \"search\"))\n",
    "            )\n",
    "            search_input.clear()\n",
    "            search_input.send_keys(query)\n",
    "            search_input.send_keys(Keys.RETURN)\n",
    "            \n",
    "            # Handle potential Search Results page (disambiguation)\n",
    "            try:\n",
    "                # We wait briefly for a search results indicator\n",
    "                WebDriverWait(driver, 3).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"mw-search-results\"))\n",
    "                )\n",
    "                # If found, click the very first result\n",
    "                first_result = driver.find_element(By.CSS_SELECTOR, \"ul.mw-search-results li a\")\n",
    "                first_result.click()\n",
    "            except:\n",
    "                # If timeout, we assume the direct article page loaded successfully\n",
    "                pass\n",
    "            \n",
    "            # Parse the final page source to find the decimal coordinates\n",
    "            time.sleep(1) # Small buffer\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Coordinates are usually in the span with class \"geo\" (decimal format: lat; lon)\n",
    "            geo_tag = soup.find(\"span\", {\"class\": \"geo\"})\n",
    "            \n",
    "            if geo_tag:\n",
    "                coords_text = geo_tag.get_text()\n",
    "                if ';' in coords_text:\n",
    "                    lat, lon = coords_text.split(';')\n",
    "                    # Convert to float and store\n",
    "                    df_result.at[index, 'Latitude'] = float(lat.strip())\n",
    "                    df_result.at[index, 'Longitude'] = float(lon.strip())\n",
    "                    print(f\"✅ Found {city}: {lat.strip()}, {lon.strip()}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Format issue for {city}: Text found but parsing failed.\")\n",
    "            else:\n",
    "                print(f\"❌ Coordinates not found for {city}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ General error processing {city}: {e}\")\n",
    "\n",
    "    # Close the browser instance\n",
    "    driver.quit()\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the cleaned data (or use the in-memory 'city_data')\n",
    "city_data_from_cleaned = pd.read_csv('city_data_cleaned.csv')\n",
    "\n",
    "# 2. Execute the scraping function\n",
    "city_data_with_coords = scrape_city_coordinates_robust(city_data_from_cleaned)\n",
    "\n",
    "# 3. Save the enriched data to a new CSV file\n",
    "# This prevents needing to re-scrape all 84 cities every time the notebook is run!\n",
    "city_data_with_coords.to_csv('city_data_with_coords.csv', index=False)\n",
    "print(\"\\n--- Data successfully scraped and saved to 'city_data_with_coords.csv' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16800df4",
   "metadata": {},
   "source": [
    "### 3. Interactive Map Visualization\n",
    "\n",
    "Using the newly acquired **Latitude** and **Longitude** data, we construct an interactive map with **Plotly Express**. This map provides a visual interface for comparing cities across Europe.\n",
    "\n",
    "**Map Features (as required):**\n",
    "\n",
    "* **Marker Size:** Scales by **Population**.\n",
    "* **Marker Color:** Scales by **Average Monthly Salary** (for visual insight).\n",
    "* **Hover Text (Tooltip):** Displays **Country**, **Population**, **Average Monthly Salary**, and **Average Cost of Living**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043aed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, ensuring coordinates are included (using the file saved above)\n",
    "city_data_final = pd.read_csv('city_data_with_coords.csv')\n",
    "\n",
    "# Filter out any rows that failed scraping (where Latitude is missing)\n",
    "map_df = city_data_final.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "if not map_df.empty:\n",
    "    fig_map = px.scatter_mapbox(\n",
    "        map_df,\n",
    "        lat=\"Latitude\",\n",
    "        lon=\"Longitude\",\n",
    "        hover_name=\"City\",\n",
    "        # Custom tooltip content\n",
    "        hover_data={\n",
    "            \"Latitude\": False,\n",
    "            \"Longitude\": False,\n",
    "            \"Country\": True,\n",
    "            \"Population\": ':,', \n",
    "            \"Average Monthly Salary\": ':,.0f €', \n",
    "            \"Average Cost of Living\": ':,.0f €'  \n",
    "        },\n",
    "        color=\"Average Monthly Salary\", \n",
    "        size=\"Population\",              \n",
    "        color_continuous_scale=\"Viridis\",\n",
    "        zoom=3, # Initial zoom level for Europe\n",
    "        height=700,\n",
    "        title=\"Interactive Map of European Cities\"\n",
    "    )\n",
    "\n",
    "    # Set map style (OpenStreetMap is free and detailed)\n",
    "    fig_map.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig_map.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "    fig_map.show()\n",
    "else:\n",
    "    print(\"Map generation skipped: Coordinate data is missing. Please run the scraping cell above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
